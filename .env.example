# ========================================
# Short Generation Core Settings
# ========================================

TARGET_RATIO_W=9              # Width part of target aspect ratio
TARGET_RATIO_H=16             # Height part (9:16 for TikTok/Shorts/Reels)
SCENE_LIMIT=4                 # Maximum clips per source video
X_CENTER=0.5                  # Horizontal crop center [0.0-1.0]
Y_CENTER=0.5                  # Vertical crop center [0.0-1.0]
MAX_ERROR_DEPTH=3             # Retry attempts for failed renders
MIN_SHORT_LENGTH=15           # Minimum clip duration (seconds)
MAX_SHORT_LENGTH=179          # Maximum clip duration (seconds)
MAX_COMBINED_SCENE_LENGTH=300 # Max combined scene length (seconds)

# ========================================
# AI Provider Configuration
# ========================================

# Provider selection: gemini, openai, or local (no API calls)
AI_PROVIDER=openai

# Enable/disable AI analysis (set to false for pure heuristic mode)
AI_ANALYSIS_ENABLED=true

# API Keys (set the one matching your AI_PROVIDER)
GEMINI_API_KEY=your-gemini-api-key
OPENAI_API_KEY=your-openai-api-key

# Model selection
# Free tier limits (daily):
#   1M tokens: gpt-5.2, gpt-5.1, gpt-5, gpt-4.1, gpt-4o, o1, o3
#   10M tokens: gpt-5-mini, gpt-4o-mini, gpt-4.1-mini, o1-mini, o3-mini, o4-mini
# Recommendation: gpt-5-mini has vision on par with GPT-5, with 10x more free tokens!
GEMINI_MODEL=gemini-2.0-flash
OPENAI_MODEL=gpt-5-mini

# Model for caption tagging/enhancement (text-only, uses mini model for efficiency)
OPENAI_TAGGING_MODEL=gpt-5-mini

# AI scoring weight (0.0-1.0, higher = more weight on AI score vs heuristic)
AI_SCORE_WEIGHT=0.7

# ========================================
# Semantic Analysis Settings
# ========================================

# Analysis goal:
#   action     - Focus on intense action moments
#   funny      - Focus on funny/fail moments
#   highlight  - Focus on memorable achievements
#   mixed      - Auto-detect best category per clip (recommended)
SEMANTIC_GOAL=mixed

# Number of top candidate clips to send to AI for analysis
CANDIDATE_CLIP_COUNT=10

# Duration of each candidate clip in seconds (shorter = cheaper API calls)
CANDIDATE_CLIP_DURATION=120

# ========================================
# Subtitle Settings
# ========================================

# Enable/disable subtitle generation
ENABLE_SUBTITLES=true

# Subtitle mode:
#   speech      - Use Whisper to transcribe voice/commentary
#   ai_captions - Use AI to generate contextual captions (for gameplay without voice)
#   none        - Skip subtitle generation entirely
SUBTITLE_MODE=ai_captions

# Whisper model (for speech mode): tiny, base, small, medium, large
WHISPER_MODEL=medium

# AI Caption settings (for ai_captions mode)
# Style options:
#   gaming   - "HEADSHOT!", "GG EZ", punchy gaming captions
#   dramatic - "The final stand.", cinematic captions
#   funny    - "skill issue tbh", meme-style captions
#   minimal  - "nice.", understated captions
#   auto     - Automatically match style to detected category (recommended)
CAPTION_STYLE=auto
MAX_CAPTIONS=8                # Maximum captions per clip

# PyCaps Template
# Available: default, vibrant, model, word-focus, hype, line-focus,
#            retro-gaming, neo-minimal, minimalist, classic, fast, explosive
PYCAPS_TEMPLATE=hype

# ========================================
# AI Caption Enhancement (Local AI Tagging)
# Uses your existing OpenAI/Gemini API
# ========================================

# Enable/disable AI caption enhancement (semantic tagging + emojis)
ENABLE_AI_CAPTION_ENHANCEMENT=true

# Add AI-suggested emojis to captions (e.g., "HEADSHOT! ðŸ’€ðŸ”¥")
ENABLE_CAPTION_EMOJIS=true

# ========================================
# TTS Voiceover Settings (ChatterBox)
# ========================================

# Enable/disable AI voiceover generation
ENABLE_TTS=true

# TTS model: chatterbox (recommended for RTX cards)
TTS_MODEL=chatterbox

# Device for TTS inference: cuda, cpu
TTS_DEVICE=cuda

# Language for TTS (auto-selects model)
# - "en" = English model with emotion/exaggeration control (default)
# - Other languages use Multilingual model (no emotion control):
#   ar (Arabic), da (Danish), de (German), el (Greek), es (Spanish),
#   fi (Finnish), fr (French), he (Hebrew), hi (Hindi), it (Italian),
#   ja (Japanese), ko (Korean), ms (Malay), nl (Dutch), no (Norwegian),
#   pl (Polish), pt (Portuguese), ru (Russian), sv (Swedish), sw (Swahili),
#   tr (Turkish), zh (Chinese)
TTS_LANGUAGE=en

# Emotion/exaggeration level (0.0 = monotone, 1.0 = dramatic)
# Only works for English model. Set to "auto" to match detected category.
# Ignored when using non-English languages (Multilingual model).
TTS_EMOTION_LEVEL=auto

# Speech speed multiplier (0.5 = half speed, 2.0 = double speed)
TTS_SPEED=1.0

# Optional: Path to reference audio for voice cloning
# Leave empty to use default voice
TTS_VOICE_REFERENCE=

# Audio mixing settings
TTS_GAME_AUDIO_VOLUME=0.3     # Lower game audio when voiceover plays
TTS_VOICEOVER_VOLUME=1.0      # Voiceover volume

# ========================================
# Decord Video Loader Settings
# ========================================

DECORD_EOF_RETRY_MAX=65536    # Retry attempts for EOF issues
DECORD_SKIP_TAIL_FRAMES=0     # Frames to skip at end (try 180-300 if hanging)

# ========================================
# Debug Variables (uncomment to enable)
# ========================================

# DEBUG_SKIP_ANALYSIS=1
# DEBUG_SKIP_RENDER=1
# DEBUG_RENDERED_CLIPS="path1:category,path2"