# AutoShorts: Flow Diagram Documentation

This file documents the end-to-end flow for AutoShorts. The system processes videos through distinct phases: Analysis, Selection, Rendering, and Content Generation (Subtitles/TTS).

## Architecture Overview

```
src/
â”œâ”€â”€ ai_providers.py         # AI Provider abstraction (Gemini, OpenAI, Local)
â”œâ”€â”€ shorts.py               # Main pipeline orchestration
â”œâ”€â”€ subtitle_generator.py   # Subtitle generation + PyCaps rendering
â”œâ”€â”€ tts_generator.py        # Qwen3-TTS VoiceDesign + audio mixing
â”œâ”€â”€ story_narrator.py       # Unified story narration generation
â””â”€â”€ dashboard/              # Streamlit UI (optional)
```

## Key Flows

### 1. Scene Selection Flow

```
Input Video
    â”‚
    â”œâ”€â”€ GEMINI_DEEP_ANALYSIS=true â”€â”€â–º ðŸ§  Deep Analysis Mode
    â”‚                                  â€¢ Gemini scans full video
    â”‚                                  â€¢ Finds highlight moments directly
    â”‚                                  â€¢ Bypasses heuristic scoring
    â”‚
    â””â”€â”€ GEMINI_DEEP_ANALYSIS=false â”€â”€â–º Heuristic + AI Ranking
                                        â€¢ Scene detection
                                        â€¢ Audio/video action scoring
                                        â€¢ Optional AI semantic ranking
```

### 2. Story Mode Subtitle Flow (NEW - TTS-First Architecture)

The critical fix for story mode ensures subtitles are not lost when TTS extends video:

```
Story Narration Generated
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Generate TTS FIRST           â”‚  â—„â”€â”€ Measure actual audio duration
â”‚    Qwen3-TTS VoiceDesign        â”‚
â”‚    Save to .story_tts.wav       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
    TTS > Video + 1s?
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
   Yes        No
    â”‚         â”‚
    â–¼         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Re-render Video    â”‚  â”‚ Use original   â”‚
â”‚    BEFORE PyCaps      â”‚  â”‚ video          â”‚
â”‚    Extend to TTS      â”‚  â”‚                â”‚
â”‚    duration           â”‚  â”‚                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                        â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Apply PyCaps Subtitles       â”‚  â—„â”€â”€ On correctly-sized video!
â”‚    Output: .mp4 format          â”‚
â”‚    Detect: SRT-based _sub.mp4   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Mix Pre-generated TTS        â”‚  â—„â”€â”€ No re-render needed
â”‚    render_meta=None             â”‚      Video already correct size
â”‚    Preserves subtitles!         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
      Final Video
    (Subtitles + TTS)
```

### 3. PyCaps Output Detection

PyCaps may save output with different naming conventions:

```python
# Detection priority order:
1. output_path                    # What we requested
2. srt_path.stem + "_sub.mp4"     # Based on SRT filename (scene-0_sub.mp4)
3. video_path.stem + "_sub.mp4"   # Based on video filename
4. _check_for_fallback_output()   # Recent output_*.mp4 files
5. FFmpeg fallback                # Last resort
```

### 4. Audio Mixing

```
Video (with subtitles)
         â”‚
         â–¼
    Has audio stream?
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
   Yes        No (PyCaps output)
    â”‚         â”‚
    â–¼         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ amix: blend      â”‚  â”‚ Add TTS as only  â”‚
â”‚ game + TTS       â”‚  â”‚ audio track      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Main Processing Flow (Mermaid)

See `flow_diagram.mmd` for the full Mermaid diagram, rendered to `flow_diagram.png`.

![Flow Diagram](flow_diagram.png)

## Key Configuration (.env)

| Variable | Description |
|----------|-------------|
| `GEMINI_DEEP_ANALYSIS` | Enable full-video Deep Analysis mode |
| `AI_PROVIDER` | gemini, openai, local |
| `AI_ANALYSIS_ENABLED` | Enable AI scene ranking |
| `ENABLE_SUBTITLES` | Generate/burn subtitles |
| `ENABLE_TTS` | Generate voiceover |
| `SUBTITLE_MODE` | speech, ai_captions, story_* modes |
| `CAPTION_STYLE` | gaming, dramatic, story_roast, story_dramatic, etc. |
| `TTS_LANGUAGE` | en, ja, ko, zh, de, fr, ru, pt, es, it |
| `TTS_GAME_AUDIO_VOLUME` | Game audio volume when mixed (default: 0.3) |
| `TTS_VOICEOVER_VOLUME` | TTS volume (default: 1.0) |

## Story Modes

| Mode | Voice Preset | Description |
|------|--------------|-------------|
| `story_news` | Male esports broadcaster | Energetic, fast-paced |
| `story_roast` | Male sarcastic comedian | Playful mockery |
| `story_dramatic` | Female theatrical narrator | Epic, momentous |
| `story_creepypasta` | Male ominous voice | Dark, unsettling |

## Multi-Language Support

When `TTS_LANGUAGE` is set to a non-English language:

- AI captions/narration generated in target language
- Culturally appropriate style adaptations
- Voice presets use English descriptions (TTS understands regardless)

## Key Optimizations

1. **Story Mode TTS-First**: Video extended BEFORE subtitles to prevent loss
2. **PyCaps Detection**: Multiple fallback paths for output detection  
3. **No-Audio Fallback**: Handle PyCaps outputs without audio tracks
4. **VRAM Management**: Unload models between phases
5. **Re-render Only When Needed**: TTS > clip + 1.5s threshold

---

*File: docs/flow_diagram.md*  
*Updated: 2026-02-08 - Story Mode TTS-First Architecture*
